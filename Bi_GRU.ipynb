{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOH6xsugY6LqaNkrLUldb/C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sashi8a/ML_Commodities_VIP_Sp26/blob/main/Bi_GRU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CLgxXnet6rY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load in Data, split into train/val/test"
      ],
      "metadata": {
        "id": "kxmH8Rs8yRG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"processed_data.csv\")\n",
        "df[\"Date\"] = pd.to_datetime(df[\"Date\"])"
      ],
      "metadata": {
        "id": "ZxGqfFRXuGeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = df[df[\"Date\"] <= pd.Timestamp(\"2021-12-01\")]\n",
        "val = df[(df[\"Date\"] > pd.Timestamp(\"2021-12-01\")) & (df[\"Date\"] <= pd.Timestamp(\"2024-12-01\"))]\n",
        "test = df[df[\"Date\"] > pd.Timestamp(\"2024-12-01\")]"
      ],
      "metadata": {
        "id": "cRld2t5svM0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.head(40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OhjkvZy-xzG_",
        "outputId": "2823ed63-ae14-48a6-d858-3e31feb8e66f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Date  Price     sasdate       RPI  W875RX1   CMRMTSPLx  IPFPNSS  \\\n",
              "0  1983-03-31  29.27  1983-03-01  6319.274   5489.2  535378.168  55.2854   \n",
              "1  1983-04-04  29.44  1983-04-01  6351.636   5514.5  543698.110  55.6149   \n",
              "2  1983-04-05  29.71  1983-04-01  6351.636   5514.5  543698.110  55.6149   \n",
              "3  1983-04-06  29.90  1983-04-01  6351.636   5514.5  543698.110  55.6149   \n",
              "4  1983-04-07  30.17  1983-04-01  6351.636   5514.5  543698.110  55.6149   \n",
              "5  1983-04-08  30.38  1983-04-01  6351.636   5514.5  543698.110  55.6149   \n",
              "6  1983-04-11  30.25  1983-04-01  6351.636   5514.5  543698.110  55.6149   \n",
              "7  1983-04-12  30.83  1983-04-01  6351.636   5514.5  543698.110  55.6149   \n",
              "8  1983-04-13  30.82  1983-04-01  6351.636   5514.5  543698.110  55.6149   \n",
              "9  1983-04-14  30.82  1983-04-01  6351.636   5514.5  543698.110  55.6149   \n",
              "10 1983-04-15  30.48  1983-04-01  6351.636   5514.5  543698.110  55.6149   \n",
              "11 1983-04-18  30.75  1983-04-01  6351.636   5514.5  543698.110  55.6149   \n",
              "12 1983-04-19  30.75  1983-04-01  6351.636   5514.5  543698.110  55.6149   \n",
              "13 1983-04-20  30.70  1983-04-01  6351.636   5514.5  543698.110  55.6149   \n",
              "14 1983-04-21  30.68  1983-04-01  6351.636   5514.5  543698.110  55.6149   \n",
              "15 1983-04-22  30.75  1983-04-01  6351.636   5514.5  543698.110  55.6149   \n",
              "16 1983-04-25  30.84  1983-04-01  6351.636   5514.5  543698.110  55.6149   \n",
              "17 1983-04-26  30.71  1983-04-01  6351.636   5514.5  543698.110  55.6149   \n",
              "18 1983-04-27  30.78  1983-04-01  6351.636   5514.5  543698.110  55.6149   \n",
              "19 1983-04-28  30.74  1983-04-01  6351.636   5514.5  543698.110  55.6149   \n",
              "20 1983-04-29  30.63  1983-04-01  6351.636   5514.5  543698.110  55.6149   \n",
              "21 1983-05-02  30.61  1983-05-01  6360.300   5529.9  557666.817  55.8776   \n",
              "22 1983-05-03  30.50  1983-05-01  6360.300   5529.9  557666.817  55.8776   \n",
              "23 1983-05-04  30.42  1983-05-01  6360.300   5529.9  557666.817  55.8776   \n",
              "24 1983-05-05  30.20  1983-05-01  6360.300   5529.9  557666.817  55.8776   \n",
              "25 1983-05-06  30.12  1983-05-01  6360.300   5529.9  557666.817  55.8776   \n",
              "26 1983-05-09  30.10  1983-05-01  6360.300   5529.9  557666.817  55.8776   \n",
              "27 1983-05-10  30.31  1983-05-01  6360.300   5529.9  557666.817  55.8776   \n",
              "28 1983-05-11  29.97  1983-05-01  6360.300   5529.9  557666.817  55.8776   \n",
              "29 1983-05-12  29.72  1983-05-01  6360.300   5529.9  557666.817  55.8776   \n",
              "30 1983-05-13  29.80  1983-05-01  6360.300   5529.9  557666.817  55.8776   \n",
              "31 1983-05-16  30.12  1983-05-01  6360.300   5529.9  557666.817  55.8776   \n",
              "32 1983-05-17  29.91  1983-05-01  6360.300   5529.9  557666.817  55.8776   \n",
              "33 1983-05-18  29.75  1983-05-01  6360.300   5529.9  557666.817  55.8776   \n",
              "34 1983-05-19  29.95  1983-05-01  6360.300   5529.9  557666.817  55.8776   \n",
              "35 1983-05-20  30.30  1983-05-01  6360.300   5529.9  557666.817  55.8776   \n",
              "36 1983-05-23  30.27  1983-05-01  6360.300   5529.9  557666.817  55.8776   \n",
              "37 1983-05-24  30.05  1983-05-01  6360.300   5529.9  557666.817  55.8776   \n",
              "38 1983-05-25  30.25  1983-05-01  6360.300   5529.9  557666.817  55.8776   \n",
              "39 1983-05-26  30.31  1983-05-01  6360.300   5529.9  557666.817  55.8776   \n",
              "\n",
              "    USWTRADE  USTRADE  BUSLOANS  ...  T5YFFM  T10YFFM  AAAFFM  BAAFFM  \\\n",
              "0     4478.5  10509.0  392.4259  ...    1.22     1.60    2.71    4.49   \n",
              "1     4491.5  10541.3  391.4906  ...    1.40     1.75    2.83    4.46   \n",
              "2     4491.5  10541.3  391.4906  ...    1.40     1.75    2.83    4.46   \n",
              "3     4491.5  10541.3  391.4906  ...    1.40     1.75    2.83    4.46   \n",
              "4     4491.5  10541.3  391.4906  ...    1.40     1.75    2.83    4.46   \n",
              "5     4491.5  10541.3  391.4906  ...    1.40     1.75    2.83    4.46   \n",
              "6     4491.5  10541.3  391.4906  ...    1.40     1.75    2.83    4.46   \n",
              "7     4491.5  10541.3  391.4906  ...    1.40     1.75    2.83    4.46   \n",
              "8     4491.5  10541.3  391.4906  ...    1.40     1.75    2.83    4.46   \n",
              "9     4491.5  10541.3  391.4906  ...    1.40     1.75    2.83    4.46   \n",
              "10    4491.5  10541.3  391.4906  ...    1.40     1.75    2.83    4.46   \n",
              "11    4491.5  10541.3  391.4906  ...    1.40     1.75    2.83    4.46   \n",
              "12    4491.5  10541.3  391.4906  ...    1.40     1.75    2.83    4.46   \n",
              "13    4491.5  10541.3  391.4906  ...    1.40     1.75    2.83    4.46   \n",
              "14    4491.5  10541.3  391.4906  ...    1.40     1.75    2.83    4.46   \n",
              "15    4491.5  10541.3  391.4906  ...    1.40     1.75    2.83    4.46   \n",
              "16    4491.5  10541.3  391.4906  ...    1.40     1.75    2.83    4.46   \n",
              "17    4491.5  10541.3  391.4906  ...    1.40     1.75    2.83    4.46   \n",
              "18    4491.5  10541.3  391.4906  ...    1.40     1.75    2.83    4.46   \n",
              "19    4491.5  10541.3  391.4906  ...    1.40     1.75    2.83    4.46   \n",
              "20    4491.5  10541.3  391.4906  ...    1.40     1.75    2.83    4.46   \n",
              "21    4510.1  10590.3  393.8395  ...    1.65     1.87    2.76    4.39   \n",
              "22    4510.1  10590.3  393.8395  ...    1.65     1.87    2.76    4.39   \n",
              "23    4510.1  10590.3  393.8395  ...    1.65     1.87    2.76    4.39   \n",
              "24    4510.1  10590.3  393.8395  ...    1.65     1.87    2.76    4.39   \n",
              "25    4510.1  10590.3  393.8395  ...    1.65     1.87    2.76    4.39   \n",
              "26    4510.1  10590.3  393.8395  ...    1.65     1.87    2.76    4.39   \n",
              "27    4510.1  10590.3  393.8395  ...    1.65     1.87    2.76    4.39   \n",
              "28    4510.1  10590.3  393.8395  ...    1.65     1.87    2.76    4.39   \n",
              "29    4510.1  10590.3  393.8395  ...    1.65     1.87    2.76    4.39   \n",
              "30    4510.1  10590.3  393.8395  ...    1.65     1.87    2.76    4.39   \n",
              "31    4510.1  10590.3  393.8395  ...    1.65     1.87    2.76    4.39   \n",
              "32    4510.1  10590.3  393.8395  ...    1.65     1.87    2.76    4.39   \n",
              "33    4510.1  10590.3  393.8395  ...    1.65     1.87    2.76    4.39   \n",
              "34    4510.1  10590.3  393.8395  ...    1.65     1.87    2.76    4.39   \n",
              "35    4510.1  10590.3  393.8395  ...    1.65     1.87    2.76    4.39   \n",
              "36    4510.1  10590.3  393.8395  ...    1.65     1.87    2.76    4.39   \n",
              "37    4510.1  10590.3  393.8395  ...    1.65     1.87    2.76    4.39   \n",
              "38    4510.1  10590.3  393.8395  ...    1.65     1.87    2.76    4.39   \n",
              "39    4510.1  10590.3  393.8395  ...    1.65     1.87    2.76    4.39   \n",
              "\n",
              "    EXSZUSx   EXJPUSx  EXUSUKx  EXCAUSx  PPICMM  UMCSENTx  \n",
              "0    2.0587  237.7467   1.5361   1.2325   102.1      89.1  \n",
              "1    2.0572  234.7557   1.5722   1.2292   103.3      93.3  \n",
              "2    2.0572  234.7557   1.5722   1.2292   103.3      93.3  \n",
              "3    2.0572  234.7557   1.5722   1.2292   103.3      93.3  \n",
              "4    2.0572  234.7557   1.5722   1.2292   103.3      93.3  \n",
              "5    2.0572  234.7557   1.5722   1.2292   103.3      93.3  \n",
              "6    2.0572  234.7557   1.5722   1.2292   103.3      93.3  \n",
              "7    2.0572  234.7557   1.5722   1.2292   103.3      93.3  \n",
              "8    2.0572  234.7557   1.5722   1.2292   103.3      93.3  \n",
              "9    2.0572  234.7557   1.5722   1.2292   103.3      93.3  \n",
              "10   2.0572  234.7557   1.5722   1.2292   103.3      93.3  \n",
              "11   2.0572  234.7557   1.5722   1.2292   103.3      93.3  \n",
              "12   2.0572  234.7557   1.5722   1.2292   103.3      93.3  \n",
              "13   2.0572  234.7557   1.5722   1.2292   103.3      93.3  \n",
              "14   2.0572  234.7557   1.5722   1.2292   103.3      93.3  \n",
              "15   2.0572  234.7557   1.5722   1.2292   103.3      93.3  \n",
              "16   2.0572  234.7557   1.5722   1.2292   103.3      93.3  \n",
              "17   2.0572  234.7557   1.5722   1.2292   103.3      93.3  \n",
              "18   2.0572  234.7557   1.5722   1.2292   103.3      93.3  \n",
              "19   2.0572  234.7557   1.5722   1.2292   103.3      93.3  \n",
              "20   2.0572  234.7557   1.5722   1.2292   103.3      93.3  \n",
              "21   2.1123  240.0314   1.5480   1.2323   102.4      92.2  \n",
              "22   2.1123  240.0314   1.5480   1.2323   102.4      92.2  \n",
              "23   2.1123  240.0314   1.5480   1.2323   102.4      92.2  \n",
              "24   2.1123  240.0314   1.5480   1.2323   102.4      92.2  \n",
              "25   2.1123  240.0314   1.5480   1.2323   102.4      92.2  \n",
              "26   2.1123  240.0314   1.5480   1.2323   102.4      92.2  \n",
              "27   2.1123  240.0314   1.5480   1.2323   102.4      92.2  \n",
              "28   2.1123  240.0314   1.5480   1.2323   102.4      92.2  \n",
              "29   2.1123  240.0314   1.5480   1.2323   102.4      92.2  \n",
              "30   2.1123  240.0314   1.5480   1.2323   102.4      92.2  \n",
              "31   2.1123  240.0314   1.5480   1.2323   102.4      92.2  \n",
              "32   2.1123  240.0314   1.5480   1.2323   102.4      92.2  \n",
              "33   2.1123  240.0314   1.5480   1.2323   102.4      92.2  \n",
              "34   2.1123  240.0314   1.5480   1.2323   102.4      92.2  \n",
              "35   2.1123  240.0314   1.5480   1.2323   102.4      92.2  \n",
              "36   2.1123  240.0314   1.5480   1.2323   102.4      92.2  \n",
              "37   2.1123  240.0314   1.5480   1.2323   102.4      92.2  \n",
              "38   2.1123  240.0314   1.5480   1.2323   102.4      92.2  \n",
              "39   2.1123  240.0314   1.5480   1.2323   102.4      92.2  \n",
              "\n",
              "[40 rows x 34 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-827b284b-e9e9-44eb-9eca-83dbde1a8c10\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Price</th>\n",
              "      <th>sasdate</th>\n",
              "      <th>RPI</th>\n",
              "      <th>W875RX1</th>\n",
              "      <th>CMRMTSPLx</th>\n",
              "      <th>IPFPNSS</th>\n",
              "      <th>USWTRADE</th>\n",
              "      <th>USTRADE</th>\n",
              "      <th>BUSLOANS</th>\n",
              "      <th>...</th>\n",
              "      <th>T5YFFM</th>\n",
              "      <th>T10YFFM</th>\n",
              "      <th>AAAFFM</th>\n",
              "      <th>BAAFFM</th>\n",
              "      <th>EXSZUSx</th>\n",
              "      <th>EXJPUSx</th>\n",
              "      <th>EXUSUKx</th>\n",
              "      <th>EXCAUSx</th>\n",
              "      <th>PPICMM</th>\n",
              "      <th>UMCSENTx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1983-03-31</td>\n",
              "      <td>29.27</td>\n",
              "      <td>1983-03-01</td>\n",
              "      <td>6319.274</td>\n",
              "      <td>5489.2</td>\n",
              "      <td>535378.168</td>\n",
              "      <td>55.2854</td>\n",
              "      <td>4478.5</td>\n",
              "      <td>10509.0</td>\n",
              "      <td>392.4259</td>\n",
              "      <td>...</td>\n",
              "      <td>1.22</td>\n",
              "      <td>1.60</td>\n",
              "      <td>2.71</td>\n",
              "      <td>4.49</td>\n",
              "      <td>2.0587</td>\n",
              "      <td>237.7467</td>\n",
              "      <td>1.5361</td>\n",
              "      <td>1.2325</td>\n",
              "      <td>102.1</td>\n",
              "      <td>89.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1983-04-04</td>\n",
              "      <td>29.44</td>\n",
              "      <td>1983-04-01</td>\n",
              "      <td>6351.636</td>\n",
              "      <td>5514.5</td>\n",
              "      <td>543698.110</td>\n",
              "      <td>55.6149</td>\n",
              "      <td>4491.5</td>\n",
              "      <td>10541.3</td>\n",
              "      <td>391.4906</td>\n",
              "      <td>...</td>\n",
              "      <td>1.40</td>\n",
              "      <td>1.75</td>\n",
              "      <td>2.83</td>\n",
              "      <td>4.46</td>\n",
              "      <td>2.0572</td>\n",
              "      <td>234.7557</td>\n",
              "      <td>1.5722</td>\n",
              "      <td>1.2292</td>\n",
              "      <td>103.3</td>\n",
              "      <td>93.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1983-04-05</td>\n",
              "      <td>29.71</td>\n",
              "      <td>1983-04-01</td>\n",
              "      <td>6351.636</td>\n",
              "      <td>5514.5</td>\n",
              "      <td>543698.110</td>\n",
              "      <td>55.6149</td>\n",
              "      <td>4491.5</td>\n",
              "      <td>10541.3</td>\n",
              "      <td>391.4906</td>\n",
              "      <td>...</td>\n",
              "      <td>1.40</td>\n",
              "      <td>1.75</td>\n",
              "      <td>2.83</td>\n",
              "      <td>4.46</td>\n",
              "      <td>2.0572</td>\n",
              "      <td>234.7557</td>\n",
              "      <td>1.5722</td>\n",
              "      <td>1.2292</td>\n",
              "      <td>103.3</td>\n",
              "      <td>93.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1983-04-06</td>\n",
              "      <td>29.90</td>\n",
              "      <td>1983-04-01</td>\n",
              "      <td>6351.636</td>\n",
              "      <td>5514.5</td>\n",
              "      <td>543698.110</td>\n",
              "      <td>55.6149</td>\n",
              "      <td>4491.5</td>\n",
              "      <td>10541.3</td>\n",
              "      <td>391.4906</td>\n",
              "      <td>...</td>\n",
              "      <td>1.40</td>\n",
              "      <td>1.75</td>\n",
              "      <td>2.83</td>\n",
              "      <td>4.46</td>\n",
              "      <td>2.0572</td>\n",
              "      <td>234.7557</td>\n",
              "      <td>1.5722</td>\n",
              "      <td>1.2292</td>\n",
              "      <td>103.3</td>\n",
              "      <td>93.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1983-04-07</td>\n",
              "      <td>30.17</td>\n",
              "      <td>1983-04-01</td>\n",
              "      <td>6351.636</td>\n",
              "      <td>5514.5</td>\n",
              "      <td>543698.110</td>\n",
              "      <td>55.6149</td>\n",
              "      <td>4491.5</td>\n",
              "      <td>10541.3</td>\n",
              "      <td>391.4906</td>\n",
              "      <td>...</td>\n",
              "      <td>1.40</td>\n",
              "      <td>1.75</td>\n",
              "      <td>2.83</td>\n",
              "      <td>4.46</td>\n",
              "      <td>2.0572</td>\n",
              "      <td>234.7557</td>\n",
              "      <td>1.5722</td>\n",
              "      <td>1.2292</td>\n",
              "      <td>103.3</td>\n",
              "      <td>93.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1983-04-08</td>\n",
              "      <td>30.38</td>\n",
              "      <td>1983-04-01</td>\n",
              "      <td>6351.636</td>\n",
              "      <td>5514.5</td>\n",
              "      <td>543698.110</td>\n",
              "      <td>55.6149</td>\n",
              "      <td>4491.5</td>\n",
              "      <td>10541.3</td>\n",
              "      <td>391.4906</td>\n",
              "      <td>...</td>\n",
              "      <td>1.40</td>\n",
              "      <td>1.75</td>\n",
              "      <td>2.83</td>\n",
              "      <td>4.46</td>\n",
              "      <td>2.0572</td>\n",
              "      <td>234.7557</td>\n",
              "      <td>1.5722</td>\n",
              "      <td>1.2292</td>\n",
              "      <td>103.3</td>\n",
              "      <td>93.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1983-04-11</td>\n",
              "      <td>30.25</td>\n",
              "      <td>1983-04-01</td>\n",
              "      <td>6351.636</td>\n",
              "      <td>5514.5</td>\n",
              "      <td>543698.110</td>\n",
              "      <td>55.6149</td>\n",
              "      <td>4491.5</td>\n",
              "      <td>10541.3</td>\n",
              "      <td>391.4906</td>\n",
              "      <td>...</td>\n",
              "      <td>1.40</td>\n",
              "      <td>1.75</td>\n",
              "      <td>2.83</td>\n",
              "      <td>4.46</td>\n",
              "      <td>2.0572</td>\n",
              "      <td>234.7557</td>\n",
              "      <td>1.5722</td>\n",
              "      <td>1.2292</td>\n",
              "      <td>103.3</td>\n",
              "      <td>93.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1983-04-12</td>\n",
              "      <td>30.83</td>\n",
              "      <td>1983-04-01</td>\n",
              "      <td>6351.636</td>\n",
              "      <td>5514.5</td>\n",
              "      <td>543698.110</td>\n",
              "      <td>55.6149</td>\n",
              "      <td>4491.5</td>\n",
              "      <td>10541.3</td>\n",
              "      <td>391.4906</td>\n",
              "      <td>...</td>\n",
              "      <td>1.40</td>\n",
              "      <td>1.75</td>\n",
              "      <td>2.83</td>\n",
              "      <td>4.46</td>\n",
              "      <td>2.0572</td>\n",
              "      <td>234.7557</td>\n",
              "      <td>1.5722</td>\n",
              "      <td>1.2292</td>\n",
              "      <td>103.3</td>\n",
              "      <td>93.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1983-04-13</td>\n",
              "      <td>30.82</td>\n",
              "      <td>1983-04-01</td>\n",
              "      <td>6351.636</td>\n",
              "      <td>5514.5</td>\n",
              "      <td>543698.110</td>\n",
              "      <td>55.6149</td>\n",
              "      <td>4491.5</td>\n",
              "      <td>10541.3</td>\n",
              "      <td>391.4906</td>\n",
              "      <td>...</td>\n",
              "      <td>1.40</td>\n",
              "      <td>1.75</td>\n",
              "      <td>2.83</td>\n",
              "      <td>4.46</td>\n",
              "      <td>2.0572</td>\n",
              "      <td>234.7557</td>\n",
              "      <td>1.5722</td>\n",
              "      <td>1.2292</td>\n",
              "      <td>103.3</td>\n",
              "      <td>93.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1983-04-14</td>\n",
              "      <td>30.82</td>\n",
              "      <td>1983-04-01</td>\n",
              "      <td>6351.636</td>\n",
              "      <td>5514.5</td>\n",
              "      <td>543698.110</td>\n",
              "      <td>55.6149</td>\n",
              "      <td>4491.5</td>\n",
              "      <td>10541.3</td>\n",
              "      <td>391.4906</td>\n",
              "      <td>...</td>\n",
              "      <td>1.40</td>\n",
              "      <td>1.75</td>\n",
              "      <td>2.83</td>\n",
              "      <td>4.46</td>\n",
              "      <td>2.0572</td>\n",
              "      <td>234.7557</td>\n",
              "      <td>1.5722</td>\n",
              "      <td>1.2292</td>\n",
              "      <td>103.3</td>\n",
              "      <td>93.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1983-04-15</td>\n",
              "      <td>30.48</td>\n",
              "      <td>1983-04-01</td>\n",
              "      <td>6351.636</td>\n",
              "      <td>5514.5</td>\n",
              "      <td>543698.110</td>\n",
              "      <td>55.6149</td>\n",
              "      <td>4491.5</td>\n",
              "      <td>10541.3</td>\n",
              "      <td>391.4906</td>\n",
              "      <td>...</td>\n",
              "      <td>1.40</td>\n",
              "      <td>1.75</td>\n",
              "      <td>2.83</td>\n",
              "      <td>4.46</td>\n",
              "      <td>2.0572</td>\n",
              "      <td>234.7557</td>\n",
              "      <td>1.5722</td>\n",
              "      <td>1.2292</td>\n",
              "      <td>103.3</td>\n",
              "      <td>93.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1983-04-18</td>\n",
              "      <td>30.75</td>\n",
              "      <td>1983-04-01</td>\n",
              "      <td>6351.636</td>\n",
              "      <td>5514.5</td>\n",
              "      <td>543698.110</td>\n",
              "      <td>55.6149</td>\n",
              "      <td>4491.5</td>\n",
              "      <td>10541.3</td>\n",
              "      <td>391.4906</td>\n",
              "      <td>...</td>\n",
              "      <td>1.40</td>\n",
              "      <td>1.75</td>\n",
              "      <td>2.83</td>\n",
              "      <td>4.46</td>\n",
              "      <td>2.0572</td>\n",
              "      <td>234.7557</td>\n",
              "      <td>1.5722</td>\n",
              "      <td>1.2292</td>\n",
              "      <td>103.3</td>\n",
              "      <td>93.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1983-04-19</td>\n",
              "      <td>30.75</td>\n",
              "      <td>1983-04-01</td>\n",
              "      <td>6351.636</td>\n",
              "      <td>5514.5</td>\n",
              "      <td>543698.110</td>\n",
              "      <td>55.6149</td>\n",
              "      <td>4491.5</td>\n",
              "      <td>10541.3</td>\n",
              "      <td>391.4906</td>\n",
              "      <td>...</td>\n",
              "      <td>1.40</td>\n",
              "      <td>1.75</td>\n",
              "      <td>2.83</td>\n",
              "      <td>4.46</td>\n",
              "      <td>2.0572</td>\n",
              "      <td>234.7557</td>\n",
              "      <td>1.5722</td>\n",
              "      <td>1.2292</td>\n",
              "      <td>103.3</td>\n",
              "      <td>93.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1983-04-20</td>\n",
              "      <td>30.70</td>\n",
              "      <td>1983-04-01</td>\n",
              "      <td>6351.636</td>\n",
              "      <td>5514.5</td>\n",
              "      <td>543698.110</td>\n",
              "      <td>55.6149</td>\n",
              "      <td>4491.5</td>\n",
              "      <td>10541.3</td>\n",
              "      <td>391.4906</td>\n",
              "      <td>...</td>\n",
              "      <td>1.40</td>\n",
              "      <td>1.75</td>\n",
              "      <td>2.83</td>\n",
              "      <td>4.46</td>\n",
              "      <td>2.0572</td>\n",
              "      <td>234.7557</td>\n",
              "      <td>1.5722</td>\n",
              "      <td>1.2292</td>\n",
              "      <td>103.3</td>\n",
              "      <td>93.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1983-04-21</td>\n",
              "      <td>30.68</td>\n",
              "      <td>1983-04-01</td>\n",
              "      <td>6351.636</td>\n",
              "      <td>5514.5</td>\n",
              "      <td>543698.110</td>\n",
              "      <td>55.6149</td>\n",
              "      <td>4491.5</td>\n",
              "      <td>10541.3</td>\n",
              "      <td>391.4906</td>\n",
              "      <td>...</td>\n",
              "      <td>1.40</td>\n",
              "      <td>1.75</td>\n",
              "      <td>2.83</td>\n",
              "      <td>4.46</td>\n",
              "      <td>2.0572</td>\n",
              "      <td>234.7557</td>\n",
              "      <td>1.5722</td>\n",
              "      <td>1.2292</td>\n",
              "      <td>103.3</td>\n",
              "      <td>93.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1983-04-22</td>\n",
              "      <td>30.75</td>\n",
              "      <td>1983-04-01</td>\n",
              "      <td>6351.636</td>\n",
              "      <td>5514.5</td>\n",
              "      <td>543698.110</td>\n",
              "      <td>55.6149</td>\n",
              "      <td>4491.5</td>\n",
              "      <td>10541.3</td>\n",
              "      <td>391.4906</td>\n",
              "      <td>...</td>\n",
              "      <td>1.40</td>\n",
              "      <td>1.75</td>\n",
              "      <td>2.83</td>\n",
              "      <td>4.46</td>\n",
              "      <td>2.0572</td>\n",
              "      <td>234.7557</td>\n",
              "      <td>1.5722</td>\n",
              "      <td>1.2292</td>\n",
              "      <td>103.3</td>\n",
              "      <td>93.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1983-04-25</td>\n",
              "      <td>30.84</td>\n",
              "      <td>1983-04-01</td>\n",
              "      <td>6351.636</td>\n",
              "      <td>5514.5</td>\n",
              "      <td>543698.110</td>\n",
              "      <td>55.6149</td>\n",
              "      <td>4491.5</td>\n",
              "      <td>10541.3</td>\n",
              "      <td>391.4906</td>\n",
              "      <td>...</td>\n",
              "      <td>1.40</td>\n",
              "      <td>1.75</td>\n",
              "      <td>2.83</td>\n",
              "      <td>4.46</td>\n",
              "      <td>2.0572</td>\n",
              "      <td>234.7557</td>\n",
              "      <td>1.5722</td>\n",
              "      <td>1.2292</td>\n",
              "      <td>103.3</td>\n",
              "      <td>93.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1983-04-26</td>\n",
              "      <td>30.71</td>\n",
              "      <td>1983-04-01</td>\n",
              "      <td>6351.636</td>\n",
              "      <td>5514.5</td>\n",
              "      <td>543698.110</td>\n",
              "      <td>55.6149</td>\n",
              "      <td>4491.5</td>\n",
              "      <td>10541.3</td>\n",
              "      <td>391.4906</td>\n",
              "      <td>...</td>\n",
              "      <td>1.40</td>\n",
              "      <td>1.75</td>\n",
              "      <td>2.83</td>\n",
              "      <td>4.46</td>\n",
              "      <td>2.0572</td>\n",
              "      <td>234.7557</td>\n",
              "      <td>1.5722</td>\n",
              "      <td>1.2292</td>\n",
              "      <td>103.3</td>\n",
              "      <td>93.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1983-04-27</td>\n",
              "      <td>30.78</td>\n",
              "      <td>1983-04-01</td>\n",
              "      <td>6351.636</td>\n",
              "      <td>5514.5</td>\n",
              "      <td>543698.110</td>\n",
              "      <td>55.6149</td>\n",
              "      <td>4491.5</td>\n",
              "      <td>10541.3</td>\n",
              "      <td>391.4906</td>\n",
              "      <td>...</td>\n",
              "      <td>1.40</td>\n",
              "      <td>1.75</td>\n",
              "      <td>2.83</td>\n",
              "      <td>4.46</td>\n",
              "      <td>2.0572</td>\n",
              "      <td>234.7557</td>\n",
              "      <td>1.5722</td>\n",
              "      <td>1.2292</td>\n",
              "      <td>103.3</td>\n",
              "      <td>93.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1983-04-28</td>\n",
              "      <td>30.74</td>\n",
              "      <td>1983-04-01</td>\n",
              "      <td>6351.636</td>\n",
              "      <td>5514.5</td>\n",
              "      <td>543698.110</td>\n",
              "      <td>55.6149</td>\n",
              "      <td>4491.5</td>\n",
              "      <td>10541.3</td>\n",
              "      <td>391.4906</td>\n",
              "      <td>...</td>\n",
              "      <td>1.40</td>\n",
              "      <td>1.75</td>\n",
              "      <td>2.83</td>\n",
              "      <td>4.46</td>\n",
              "      <td>2.0572</td>\n",
              "      <td>234.7557</td>\n",
              "      <td>1.5722</td>\n",
              "      <td>1.2292</td>\n",
              "      <td>103.3</td>\n",
              "      <td>93.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1983-04-29</td>\n",
              "      <td>30.63</td>\n",
              "      <td>1983-04-01</td>\n",
              "      <td>6351.636</td>\n",
              "      <td>5514.5</td>\n",
              "      <td>543698.110</td>\n",
              "      <td>55.6149</td>\n",
              "      <td>4491.5</td>\n",
              "      <td>10541.3</td>\n",
              "      <td>391.4906</td>\n",
              "      <td>...</td>\n",
              "      <td>1.40</td>\n",
              "      <td>1.75</td>\n",
              "      <td>2.83</td>\n",
              "      <td>4.46</td>\n",
              "      <td>2.0572</td>\n",
              "      <td>234.7557</td>\n",
              "      <td>1.5722</td>\n",
              "      <td>1.2292</td>\n",
              "      <td>103.3</td>\n",
              "      <td>93.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1983-05-02</td>\n",
              "      <td>30.61</td>\n",
              "      <td>1983-05-01</td>\n",
              "      <td>6360.300</td>\n",
              "      <td>5529.9</td>\n",
              "      <td>557666.817</td>\n",
              "      <td>55.8776</td>\n",
              "      <td>4510.1</td>\n",
              "      <td>10590.3</td>\n",
              "      <td>393.8395</td>\n",
              "      <td>...</td>\n",
              "      <td>1.65</td>\n",
              "      <td>1.87</td>\n",
              "      <td>2.76</td>\n",
              "      <td>4.39</td>\n",
              "      <td>2.1123</td>\n",
              "      <td>240.0314</td>\n",
              "      <td>1.5480</td>\n",
              "      <td>1.2323</td>\n",
              "      <td>102.4</td>\n",
              "      <td>92.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>1983-05-03</td>\n",
              "      <td>30.50</td>\n",
              "      <td>1983-05-01</td>\n",
              "      <td>6360.300</td>\n",
              "      <td>5529.9</td>\n",
              "      <td>557666.817</td>\n",
              "      <td>55.8776</td>\n",
              "      <td>4510.1</td>\n",
              "      <td>10590.3</td>\n",
              "      <td>393.8395</td>\n",
              "      <td>...</td>\n",
              "      <td>1.65</td>\n",
              "      <td>1.87</td>\n",
              "      <td>2.76</td>\n",
              "      <td>4.39</td>\n",
              "      <td>2.1123</td>\n",
              "      <td>240.0314</td>\n",
              "      <td>1.5480</td>\n",
              "      <td>1.2323</td>\n",
              "      <td>102.4</td>\n",
              "      <td>92.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>1983-05-04</td>\n",
              "      <td>30.42</td>\n",
              "      <td>1983-05-01</td>\n",
              "      <td>6360.300</td>\n",
              "      <td>5529.9</td>\n",
              "      <td>557666.817</td>\n",
              "      <td>55.8776</td>\n",
              "      <td>4510.1</td>\n",
              "      <td>10590.3</td>\n",
              "      <td>393.8395</td>\n",
              "      <td>...</td>\n",
              "      <td>1.65</td>\n",
              "      <td>1.87</td>\n",
              "      <td>2.76</td>\n",
              "      <td>4.39</td>\n",
              "      <td>2.1123</td>\n",
              "      <td>240.0314</td>\n",
              "      <td>1.5480</td>\n",
              "      <td>1.2323</td>\n",
              "      <td>102.4</td>\n",
              "      <td>92.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>1983-05-05</td>\n",
              "      <td>30.20</td>\n",
              "      <td>1983-05-01</td>\n",
              "      <td>6360.300</td>\n",
              "      <td>5529.9</td>\n",
              "      <td>557666.817</td>\n",
              "      <td>55.8776</td>\n",
              "      <td>4510.1</td>\n",
              "      <td>10590.3</td>\n",
              "      <td>393.8395</td>\n",
              "      <td>...</td>\n",
              "      <td>1.65</td>\n",
              "      <td>1.87</td>\n",
              "      <td>2.76</td>\n",
              "      <td>4.39</td>\n",
              "      <td>2.1123</td>\n",
              "      <td>240.0314</td>\n",
              "      <td>1.5480</td>\n",
              "      <td>1.2323</td>\n",
              "      <td>102.4</td>\n",
              "      <td>92.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>1983-05-06</td>\n",
              "      <td>30.12</td>\n",
              "      <td>1983-05-01</td>\n",
              "      <td>6360.300</td>\n",
              "      <td>5529.9</td>\n",
              "      <td>557666.817</td>\n",
              "      <td>55.8776</td>\n",
              "      <td>4510.1</td>\n",
              "      <td>10590.3</td>\n",
              "      <td>393.8395</td>\n",
              "      <td>...</td>\n",
              "      <td>1.65</td>\n",
              "      <td>1.87</td>\n",
              "      <td>2.76</td>\n",
              "      <td>4.39</td>\n",
              "      <td>2.1123</td>\n",
              "      <td>240.0314</td>\n",
              "      <td>1.5480</td>\n",
              "      <td>1.2323</td>\n",
              "      <td>102.4</td>\n",
              "      <td>92.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>1983-05-09</td>\n",
              "      <td>30.10</td>\n",
              "      <td>1983-05-01</td>\n",
              "      <td>6360.300</td>\n",
              "      <td>5529.9</td>\n",
              "      <td>557666.817</td>\n",
              "      <td>55.8776</td>\n",
              "      <td>4510.1</td>\n",
              "      <td>10590.3</td>\n",
              "      <td>393.8395</td>\n",
              "      <td>...</td>\n",
              "      <td>1.65</td>\n",
              "      <td>1.87</td>\n",
              "      <td>2.76</td>\n",
              "      <td>4.39</td>\n",
              "      <td>2.1123</td>\n",
              "      <td>240.0314</td>\n",
              "      <td>1.5480</td>\n",
              "      <td>1.2323</td>\n",
              "      <td>102.4</td>\n",
              "      <td>92.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>1983-05-10</td>\n",
              "      <td>30.31</td>\n",
              "      <td>1983-05-01</td>\n",
              "      <td>6360.300</td>\n",
              "      <td>5529.9</td>\n",
              "      <td>557666.817</td>\n",
              "      <td>55.8776</td>\n",
              "      <td>4510.1</td>\n",
              "      <td>10590.3</td>\n",
              "      <td>393.8395</td>\n",
              "      <td>...</td>\n",
              "      <td>1.65</td>\n",
              "      <td>1.87</td>\n",
              "      <td>2.76</td>\n",
              "      <td>4.39</td>\n",
              "      <td>2.1123</td>\n",
              "      <td>240.0314</td>\n",
              "      <td>1.5480</td>\n",
              "      <td>1.2323</td>\n",
              "      <td>102.4</td>\n",
              "      <td>92.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>1983-05-11</td>\n",
              "      <td>29.97</td>\n",
              "      <td>1983-05-01</td>\n",
              "      <td>6360.300</td>\n",
              "      <td>5529.9</td>\n",
              "      <td>557666.817</td>\n",
              "      <td>55.8776</td>\n",
              "      <td>4510.1</td>\n",
              "      <td>10590.3</td>\n",
              "      <td>393.8395</td>\n",
              "      <td>...</td>\n",
              "      <td>1.65</td>\n",
              "      <td>1.87</td>\n",
              "      <td>2.76</td>\n",
              "      <td>4.39</td>\n",
              "      <td>2.1123</td>\n",
              "      <td>240.0314</td>\n",
              "      <td>1.5480</td>\n",
              "      <td>1.2323</td>\n",
              "      <td>102.4</td>\n",
              "      <td>92.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>1983-05-12</td>\n",
              "      <td>29.72</td>\n",
              "      <td>1983-05-01</td>\n",
              "      <td>6360.300</td>\n",
              "      <td>5529.9</td>\n",
              "      <td>557666.817</td>\n",
              "      <td>55.8776</td>\n",
              "      <td>4510.1</td>\n",
              "      <td>10590.3</td>\n",
              "      <td>393.8395</td>\n",
              "      <td>...</td>\n",
              "      <td>1.65</td>\n",
              "      <td>1.87</td>\n",
              "      <td>2.76</td>\n",
              "      <td>4.39</td>\n",
              "      <td>2.1123</td>\n",
              "      <td>240.0314</td>\n",
              "      <td>1.5480</td>\n",
              "      <td>1.2323</td>\n",
              "      <td>102.4</td>\n",
              "      <td>92.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>1983-05-13</td>\n",
              "      <td>29.80</td>\n",
              "      <td>1983-05-01</td>\n",
              "      <td>6360.300</td>\n",
              "      <td>5529.9</td>\n",
              "      <td>557666.817</td>\n",
              "      <td>55.8776</td>\n",
              "      <td>4510.1</td>\n",
              "      <td>10590.3</td>\n",
              "      <td>393.8395</td>\n",
              "      <td>...</td>\n",
              "      <td>1.65</td>\n",
              "      <td>1.87</td>\n",
              "      <td>2.76</td>\n",
              "      <td>4.39</td>\n",
              "      <td>2.1123</td>\n",
              "      <td>240.0314</td>\n",
              "      <td>1.5480</td>\n",
              "      <td>1.2323</td>\n",
              "      <td>102.4</td>\n",
              "      <td>92.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>1983-05-16</td>\n",
              "      <td>30.12</td>\n",
              "      <td>1983-05-01</td>\n",
              "      <td>6360.300</td>\n",
              "      <td>5529.9</td>\n",
              "      <td>557666.817</td>\n",
              "      <td>55.8776</td>\n",
              "      <td>4510.1</td>\n",
              "      <td>10590.3</td>\n",
              "      <td>393.8395</td>\n",
              "      <td>...</td>\n",
              "      <td>1.65</td>\n",
              "      <td>1.87</td>\n",
              "      <td>2.76</td>\n",
              "      <td>4.39</td>\n",
              "      <td>2.1123</td>\n",
              "      <td>240.0314</td>\n",
              "      <td>1.5480</td>\n",
              "      <td>1.2323</td>\n",
              "      <td>102.4</td>\n",
              "      <td>92.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>1983-05-17</td>\n",
              "      <td>29.91</td>\n",
              "      <td>1983-05-01</td>\n",
              "      <td>6360.300</td>\n",
              "      <td>5529.9</td>\n",
              "      <td>557666.817</td>\n",
              "      <td>55.8776</td>\n",
              "      <td>4510.1</td>\n",
              "      <td>10590.3</td>\n",
              "      <td>393.8395</td>\n",
              "      <td>...</td>\n",
              "      <td>1.65</td>\n",
              "      <td>1.87</td>\n",
              "      <td>2.76</td>\n",
              "      <td>4.39</td>\n",
              "      <td>2.1123</td>\n",
              "      <td>240.0314</td>\n",
              "      <td>1.5480</td>\n",
              "      <td>1.2323</td>\n",
              "      <td>102.4</td>\n",
              "      <td>92.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>1983-05-18</td>\n",
              "      <td>29.75</td>\n",
              "      <td>1983-05-01</td>\n",
              "      <td>6360.300</td>\n",
              "      <td>5529.9</td>\n",
              "      <td>557666.817</td>\n",
              "      <td>55.8776</td>\n",
              "      <td>4510.1</td>\n",
              "      <td>10590.3</td>\n",
              "      <td>393.8395</td>\n",
              "      <td>...</td>\n",
              "      <td>1.65</td>\n",
              "      <td>1.87</td>\n",
              "      <td>2.76</td>\n",
              "      <td>4.39</td>\n",
              "      <td>2.1123</td>\n",
              "      <td>240.0314</td>\n",
              "      <td>1.5480</td>\n",
              "      <td>1.2323</td>\n",
              "      <td>102.4</td>\n",
              "      <td>92.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>1983-05-19</td>\n",
              "      <td>29.95</td>\n",
              "      <td>1983-05-01</td>\n",
              "      <td>6360.300</td>\n",
              "      <td>5529.9</td>\n",
              "      <td>557666.817</td>\n",
              "      <td>55.8776</td>\n",
              "      <td>4510.1</td>\n",
              "      <td>10590.3</td>\n",
              "      <td>393.8395</td>\n",
              "      <td>...</td>\n",
              "      <td>1.65</td>\n",
              "      <td>1.87</td>\n",
              "      <td>2.76</td>\n",
              "      <td>4.39</td>\n",
              "      <td>2.1123</td>\n",
              "      <td>240.0314</td>\n",
              "      <td>1.5480</td>\n",
              "      <td>1.2323</td>\n",
              "      <td>102.4</td>\n",
              "      <td>92.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>1983-05-20</td>\n",
              "      <td>30.30</td>\n",
              "      <td>1983-05-01</td>\n",
              "      <td>6360.300</td>\n",
              "      <td>5529.9</td>\n",
              "      <td>557666.817</td>\n",
              "      <td>55.8776</td>\n",
              "      <td>4510.1</td>\n",
              "      <td>10590.3</td>\n",
              "      <td>393.8395</td>\n",
              "      <td>...</td>\n",
              "      <td>1.65</td>\n",
              "      <td>1.87</td>\n",
              "      <td>2.76</td>\n",
              "      <td>4.39</td>\n",
              "      <td>2.1123</td>\n",
              "      <td>240.0314</td>\n",
              "      <td>1.5480</td>\n",
              "      <td>1.2323</td>\n",
              "      <td>102.4</td>\n",
              "      <td>92.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>1983-05-23</td>\n",
              "      <td>30.27</td>\n",
              "      <td>1983-05-01</td>\n",
              "      <td>6360.300</td>\n",
              "      <td>5529.9</td>\n",
              "      <td>557666.817</td>\n",
              "      <td>55.8776</td>\n",
              "      <td>4510.1</td>\n",
              "      <td>10590.3</td>\n",
              "      <td>393.8395</td>\n",
              "      <td>...</td>\n",
              "      <td>1.65</td>\n",
              "      <td>1.87</td>\n",
              "      <td>2.76</td>\n",
              "      <td>4.39</td>\n",
              "      <td>2.1123</td>\n",
              "      <td>240.0314</td>\n",
              "      <td>1.5480</td>\n",
              "      <td>1.2323</td>\n",
              "      <td>102.4</td>\n",
              "      <td>92.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>1983-05-24</td>\n",
              "      <td>30.05</td>\n",
              "      <td>1983-05-01</td>\n",
              "      <td>6360.300</td>\n",
              "      <td>5529.9</td>\n",
              "      <td>557666.817</td>\n",
              "      <td>55.8776</td>\n",
              "      <td>4510.1</td>\n",
              "      <td>10590.3</td>\n",
              "      <td>393.8395</td>\n",
              "      <td>...</td>\n",
              "      <td>1.65</td>\n",
              "      <td>1.87</td>\n",
              "      <td>2.76</td>\n",
              "      <td>4.39</td>\n",
              "      <td>2.1123</td>\n",
              "      <td>240.0314</td>\n",
              "      <td>1.5480</td>\n",
              "      <td>1.2323</td>\n",
              "      <td>102.4</td>\n",
              "      <td>92.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>1983-05-25</td>\n",
              "      <td>30.25</td>\n",
              "      <td>1983-05-01</td>\n",
              "      <td>6360.300</td>\n",
              "      <td>5529.9</td>\n",
              "      <td>557666.817</td>\n",
              "      <td>55.8776</td>\n",
              "      <td>4510.1</td>\n",
              "      <td>10590.3</td>\n",
              "      <td>393.8395</td>\n",
              "      <td>...</td>\n",
              "      <td>1.65</td>\n",
              "      <td>1.87</td>\n",
              "      <td>2.76</td>\n",
              "      <td>4.39</td>\n",
              "      <td>2.1123</td>\n",
              "      <td>240.0314</td>\n",
              "      <td>1.5480</td>\n",
              "      <td>1.2323</td>\n",
              "      <td>102.4</td>\n",
              "      <td>92.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>1983-05-26</td>\n",
              "      <td>30.31</td>\n",
              "      <td>1983-05-01</td>\n",
              "      <td>6360.300</td>\n",
              "      <td>5529.9</td>\n",
              "      <td>557666.817</td>\n",
              "      <td>55.8776</td>\n",
              "      <td>4510.1</td>\n",
              "      <td>10590.3</td>\n",
              "      <td>393.8395</td>\n",
              "      <td>...</td>\n",
              "      <td>1.65</td>\n",
              "      <td>1.87</td>\n",
              "      <td>2.76</td>\n",
              "      <td>4.39</td>\n",
              "      <td>2.1123</td>\n",
              "      <td>240.0314</td>\n",
              "      <td>1.5480</td>\n",
              "      <td>1.2323</td>\n",
              "      <td>102.4</td>\n",
              "      <td>92.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>40 rows  34 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-827b284b-e9e9-44eb-9eca-83dbde1a8c10')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-827b284b-e9e9-44eb-9eca-83dbde1a8c10 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-827b284b-e9e9-44eb-9eca-83dbde1a8c10');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "zLCii0wDyDMq",
        "outputId": "cd20415b-a556-4aa2-e58a-7b520ca0daad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Date  Price     sasdate        RPI  W875RX1  CMRMTSPLx  IPFPNSS  \\\n",
              "9809 2021-12-02  66.27  2021-12-01  19062.795  15496.6  1485162.0  98.6614   \n",
              "9810 2021-12-03  66.10  2021-12-01  19062.795  15496.6  1485162.0  98.6614   \n",
              "9811 2021-12-06  69.30  2021-12-01  19062.795  15496.6  1485162.0  98.6614   \n",
              "9812 2021-12-07  71.84  2021-12-01  19062.795  15496.6  1485162.0  98.6614   \n",
              "9813 2021-12-08  72.18  2021-12-01  19062.795  15496.6  1485162.0  98.6614   \n",
              "\n",
              "      USWTRADE  USTRADE   BUSLOANS  ...  T5YFFM  T10YFFM  AAAFFM  BAAFFM  \\\n",
              "9809    5852.7  15407.9  2486.9777  ...    1.46     1.68    2.85     3.5   \n",
              "9810    5852.7  15407.9  2486.9777  ...    1.46     1.68    2.85     3.5   \n",
              "9811    5852.7  15407.9  2486.9777  ...    1.46     1.68    2.85     3.5   \n",
              "9812    5852.7  15407.9  2486.9777  ...    1.46     1.68    2.85     3.5   \n",
              "9813    5852.7  15407.9  2486.9777  ...    1.46     1.68    2.85     3.5   \n",
              "\n",
              "      EXSZUSx   EXJPUSx  EXUSUKx  EXCAUSx   PPICMM  UMCSENTx  \n",
              "9809   0.9191  114.8255   1.3555   1.2622  282.527      67.2  \n",
              "9810   0.9191  114.8255   1.3555   1.2622  282.527      67.2  \n",
              "9811   0.9191  114.8255   1.3555   1.2622  282.527      67.2  \n",
              "9812   0.9191  114.8255   1.3555   1.2622  282.527      67.2  \n",
              "9813   0.9191  114.8255   1.3555   1.2622  282.527      67.2  \n",
              "\n",
              "[5 rows x 34 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dc3f55e6-5c52-4435-9aa6-f4e5b0159c4a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Price</th>\n",
              "      <th>sasdate</th>\n",
              "      <th>RPI</th>\n",
              "      <th>W875RX1</th>\n",
              "      <th>CMRMTSPLx</th>\n",
              "      <th>IPFPNSS</th>\n",
              "      <th>USWTRADE</th>\n",
              "      <th>USTRADE</th>\n",
              "      <th>BUSLOANS</th>\n",
              "      <th>...</th>\n",
              "      <th>T5YFFM</th>\n",
              "      <th>T10YFFM</th>\n",
              "      <th>AAAFFM</th>\n",
              "      <th>BAAFFM</th>\n",
              "      <th>EXSZUSx</th>\n",
              "      <th>EXJPUSx</th>\n",
              "      <th>EXUSUKx</th>\n",
              "      <th>EXCAUSx</th>\n",
              "      <th>PPICMM</th>\n",
              "      <th>UMCSENTx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9809</th>\n",
              "      <td>2021-12-02</td>\n",
              "      <td>66.27</td>\n",
              "      <td>2021-12-01</td>\n",
              "      <td>19062.795</td>\n",
              "      <td>15496.6</td>\n",
              "      <td>1485162.0</td>\n",
              "      <td>98.6614</td>\n",
              "      <td>5852.7</td>\n",
              "      <td>15407.9</td>\n",
              "      <td>2486.9777</td>\n",
              "      <td>...</td>\n",
              "      <td>1.46</td>\n",
              "      <td>1.68</td>\n",
              "      <td>2.85</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0.9191</td>\n",
              "      <td>114.8255</td>\n",
              "      <td>1.3555</td>\n",
              "      <td>1.2622</td>\n",
              "      <td>282.527</td>\n",
              "      <td>67.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9810</th>\n",
              "      <td>2021-12-03</td>\n",
              "      <td>66.10</td>\n",
              "      <td>2021-12-01</td>\n",
              "      <td>19062.795</td>\n",
              "      <td>15496.6</td>\n",
              "      <td>1485162.0</td>\n",
              "      <td>98.6614</td>\n",
              "      <td>5852.7</td>\n",
              "      <td>15407.9</td>\n",
              "      <td>2486.9777</td>\n",
              "      <td>...</td>\n",
              "      <td>1.46</td>\n",
              "      <td>1.68</td>\n",
              "      <td>2.85</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0.9191</td>\n",
              "      <td>114.8255</td>\n",
              "      <td>1.3555</td>\n",
              "      <td>1.2622</td>\n",
              "      <td>282.527</td>\n",
              "      <td>67.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9811</th>\n",
              "      <td>2021-12-06</td>\n",
              "      <td>69.30</td>\n",
              "      <td>2021-12-01</td>\n",
              "      <td>19062.795</td>\n",
              "      <td>15496.6</td>\n",
              "      <td>1485162.0</td>\n",
              "      <td>98.6614</td>\n",
              "      <td>5852.7</td>\n",
              "      <td>15407.9</td>\n",
              "      <td>2486.9777</td>\n",
              "      <td>...</td>\n",
              "      <td>1.46</td>\n",
              "      <td>1.68</td>\n",
              "      <td>2.85</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0.9191</td>\n",
              "      <td>114.8255</td>\n",
              "      <td>1.3555</td>\n",
              "      <td>1.2622</td>\n",
              "      <td>282.527</td>\n",
              "      <td>67.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9812</th>\n",
              "      <td>2021-12-07</td>\n",
              "      <td>71.84</td>\n",
              "      <td>2021-12-01</td>\n",
              "      <td>19062.795</td>\n",
              "      <td>15496.6</td>\n",
              "      <td>1485162.0</td>\n",
              "      <td>98.6614</td>\n",
              "      <td>5852.7</td>\n",
              "      <td>15407.9</td>\n",
              "      <td>2486.9777</td>\n",
              "      <td>...</td>\n",
              "      <td>1.46</td>\n",
              "      <td>1.68</td>\n",
              "      <td>2.85</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0.9191</td>\n",
              "      <td>114.8255</td>\n",
              "      <td>1.3555</td>\n",
              "      <td>1.2622</td>\n",
              "      <td>282.527</td>\n",
              "      <td>67.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9813</th>\n",
              "      <td>2021-12-08</td>\n",
              "      <td>72.18</td>\n",
              "      <td>2021-12-01</td>\n",
              "      <td>19062.795</td>\n",
              "      <td>15496.6</td>\n",
              "      <td>1485162.0</td>\n",
              "      <td>98.6614</td>\n",
              "      <td>5852.7</td>\n",
              "      <td>15407.9</td>\n",
              "      <td>2486.9777</td>\n",
              "      <td>...</td>\n",
              "      <td>1.46</td>\n",
              "      <td>1.68</td>\n",
              "      <td>2.85</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0.9191</td>\n",
              "      <td>114.8255</td>\n",
              "      <td>1.3555</td>\n",
              "      <td>1.2622</td>\n",
              "      <td>282.527</td>\n",
              "      <td>67.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  34 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc3f55e6-5c52-4435-9aa6-f4e5b0159c4a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dc3f55e6-5c52-4435-9aa6-f4e5b0159c4a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dc3f55e6-5c52-4435-9aa6-f4e5b0159c4a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "val"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "7R6vtpXgyFR6",
        "outputId": "98e4e060-860a-4622-b212-3387ba4202d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Date  Price     sasdate        RPI  W875RX1  CMRMTSPLx  IPFPNSS  \\\n",
              "10785 2025-08-26  63.25  2025-08-01  20603.322  16654.3  1551287.0  97.7772   \n",
              "10786 2025-08-27  64.15  2025-08-01  20603.322  16654.3  1551287.0  97.7772   \n",
              "10787 2025-08-28  64.60  2025-08-01  20603.322  16654.3  1551287.0  97.7772   \n",
              "10788 2025-08-29  64.01  2025-08-01  20603.322  16654.3  1551287.0  97.7772   \n",
              "10789 2025-08-31  63.96  2025-08-01  20603.322  16654.3  1551287.0  97.7772   \n",
              "\n",
              "       USWTRADE  USTRADE   BUSLOANS  ...  T5YFFM  T10YFFM  AAAFFM  BAAFFM  \\\n",
              "10785    6165.9  15605.2  2693.7764  ...   -0.57    -0.11    0.98     1.6   \n",
              "10786    6165.9  15605.2  2693.7764  ...   -0.57    -0.11    0.98     1.6   \n",
              "10787    6165.9  15605.2  2693.7764  ...   -0.57    -0.11    0.98     1.6   \n",
              "10788    6165.9  15605.2  2693.7764  ...   -0.57    -0.11    0.98     1.6   \n",
              "10789    6165.9  15605.2  2693.7764  ...   -0.57    -0.11    0.98     1.6   \n",
              "\n",
              "       EXSZUSx   EXJPUSx  EXUSUKx  EXCAUSx  PPICMM  UMCSENTx  \n",
              "10785   0.7961  147.8629   1.3506   1.3834  387.56      55.1  \n",
              "10786   0.7961  147.8629   1.3506   1.3834  387.56      55.1  \n",
              "10787   0.7961  147.8629   1.3506   1.3834  387.56      55.1  \n",
              "10788   0.7961  147.8629   1.3506   1.3834  387.56      55.1  \n",
              "10789   0.7961  147.8629   1.3506   1.3834  387.56      55.1  \n",
              "\n",
              "[5 rows x 34 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c74103b3-6896-4e48-adb9-a7164350d654\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Price</th>\n",
              "      <th>sasdate</th>\n",
              "      <th>RPI</th>\n",
              "      <th>W875RX1</th>\n",
              "      <th>CMRMTSPLx</th>\n",
              "      <th>IPFPNSS</th>\n",
              "      <th>USWTRADE</th>\n",
              "      <th>USTRADE</th>\n",
              "      <th>BUSLOANS</th>\n",
              "      <th>...</th>\n",
              "      <th>T5YFFM</th>\n",
              "      <th>T10YFFM</th>\n",
              "      <th>AAAFFM</th>\n",
              "      <th>BAAFFM</th>\n",
              "      <th>EXSZUSx</th>\n",
              "      <th>EXJPUSx</th>\n",
              "      <th>EXUSUKx</th>\n",
              "      <th>EXCAUSx</th>\n",
              "      <th>PPICMM</th>\n",
              "      <th>UMCSENTx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10785</th>\n",
              "      <td>2025-08-26</td>\n",
              "      <td>63.25</td>\n",
              "      <td>2025-08-01</td>\n",
              "      <td>20603.322</td>\n",
              "      <td>16654.3</td>\n",
              "      <td>1551287.0</td>\n",
              "      <td>97.7772</td>\n",
              "      <td>6165.9</td>\n",
              "      <td>15605.2</td>\n",
              "      <td>2693.7764</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.57</td>\n",
              "      <td>-0.11</td>\n",
              "      <td>0.98</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.7961</td>\n",
              "      <td>147.8629</td>\n",
              "      <td>1.3506</td>\n",
              "      <td>1.3834</td>\n",
              "      <td>387.56</td>\n",
              "      <td>55.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10786</th>\n",
              "      <td>2025-08-27</td>\n",
              "      <td>64.15</td>\n",
              "      <td>2025-08-01</td>\n",
              "      <td>20603.322</td>\n",
              "      <td>16654.3</td>\n",
              "      <td>1551287.0</td>\n",
              "      <td>97.7772</td>\n",
              "      <td>6165.9</td>\n",
              "      <td>15605.2</td>\n",
              "      <td>2693.7764</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.57</td>\n",
              "      <td>-0.11</td>\n",
              "      <td>0.98</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.7961</td>\n",
              "      <td>147.8629</td>\n",
              "      <td>1.3506</td>\n",
              "      <td>1.3834</td>\n",
              "      <td>387.56</td>\n",
              "      <td>55.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10787</th>\n",
              "      <td>2025-08-28</td>\n",
              "      <td>64.60</td>\n",
              "      <td>2025-08-01</td>\n",
              "      <td>20603.322</td>\n",
              "      <td>16654.3</td>\n",
              "      <td>1551287.0</td>\n",
              "      <td>97.7772</td>\n",
              "      <td>6165.9</td>\n",
              "      <td>15605.2</td>\n",
              "      <td>2693.7764</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.57</td>\n",
              "      <td>-0.11</td>\n",
              "      <td>0.98</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.7961</td>\n",
              "      <td>147.8629</td>\n",
              "      <td>1.3506</td>\n",
              "      <td>1.3834</td>\n",
              "      <td>387.56</td>\n",
              "      <td>55.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10788</th>\n",
              "      <td>2025-08-29</td>\n",
              "      <td>64.01</td>\n",
              "      <td>2025-08-01</td>\n",
              "      <td>20603.322</td>\n",
              "      <td>16654.3</td>\n",
              "      <td>1551287.0</td>\n",
              "      <td>97.7772</td>\n",
              "      <td>6165.9</td>\n",
              "      <td>15605.2</td>\n",
              "      <td>2693.7764</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.57</td>\n",
              "      <td>-0.11</td>\n",
              "      <td>0.98</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.7961</td>\n",
              "      <td>147.8629</td>\n",
              "      <td>1.3506</td>\n",
              "      <td>1.3834</td>\n",
              "      <td>387.56</td>\n",
              "      <td>55.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10789</th>\n",
              "      <td>2025-08-31</td>\n",
              "      <td>63.96</td>\n",
              "      <td>2025-08-01</td>\n",
              "      <td>20603.322</td>\n",
              "      <td>16654.3</td>\n",
              "      <td>1551287.0</td>\n",
              "      <td>97.7772</td>\n",
              "      <td>6165.9</td>\n",
              "      <td>15605.2</td>\n",
              "      <td>2693.7764</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.57</td>\n",
              "      <td>-0.11</td>\n",
              "      <td>0.98</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.7961</td>\n",
              "      <td>147.8629</td>\n",
              "      <td>1.3506</td>\n",
              "      <td>1.3834</td>\n",
              "      <td>387.56</td>\n",
              "      <td>55.1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  34 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c74103b3-6896-4e48-adb9-a7164350d654')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c74103b3-6896-4e48-adb9-a7164350d654 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c74103b3-6896-4e48-adb9-a7164350d654');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Base Forecase Model Class template"
      ],
      "metadata": {
        "id": "SBB88GbmyeP-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Base Template for Forecasting Models\n",
        "\n",
        "This is a simple template showing what methods your model needs to have.\n",
        "\"\"\"\n",
        "\n",
        "from abc import ABC, abstractmethod\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class BaseForecastModel(ABC):\n",
        "    \"\"\"\n",
        "    Simple base class for forecasting models.\n",
        "\n",
        "    Your model should inherit from this and implement all the methods below.\n",
        "\n",
        "    Example:\n",
        "        class MyModel(BaseForecastModel):\n",
        "            def __init__(self, task_type, **params):\n",
        "                super().__init__(task_type, **params)\n",
        "                # Your setup code here\n",
        "\n",
        "            def fit(self, X_train, y_train):\n",
        "                # Your training code here\n",
        "                pass\n",
        "\n",
        "            def predict(self, X):\n",
        "                # Your prediction code here\n",
        "                return predictions\n",
        "\n",
        "            def evaluate(self, X_test, y_test):\n",
        "                # Your evaluation code here\n",
        "                return metrics\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, task_type: str, **hyperparameters):\n",
        "        \"\"\"\n",
        "        Initialize your model.\n",
        "\n",
        "        Args:\n",
        "            task_type: Either 'regression' or 'classification'\n",
        "            **hyperparameters: Your model's parameters (e.g., learning_rate=0.01)\n",
        "\n",
        "        Students should:\n",
        "            - Store the task_type\n",
        "            - Store any hyperparameters\n",
        "            - Initialize your model architecture/components\n",
        "        \"\"\"\n",
        "        self.task_type = task_type\n",
        "        self.hyperparameters = hyperparameters\n",
        "\n",
        "    @abstractmethod\n",
        "    def fit(self, X_train, y_train):\n",
        "        \"\"\"\n",
        "        Train your model on the training data.\n",
        "\n",
        "        Args:\n",
        "            X_train: Training features, shape (n_samples, n_features)\n",
        "            y_train: Training targets, shape (n_samples,)\n",
        "\n",
        "        You should implement:\n",
        "            - Data preprocessing if needed\n",
        "            - Model training logic\n",
        "            - Store trained parameters/weights\n",
        "\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Make predictions on new data.\n",
        "\n",
        "        Args:\n",
        "            X: Features to predict on, shape (n_samples, n_features)\n",
        "\n",
        "        Returns:\n",
        "            predictions: Your predictions, shape (n_samples,)\n",
        "\n",
        "        You should implement:\n",
        "            - Apply same preprocessing as in fit()\n",
        "            - Generate predictions using trained model\n",
        "            - Return predictions as numpy array\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def evaluate(self, X_test, y_test):\n",
        "        \"\"\"\n",
        "        Evaluate model performance on test data.\n",
        "\n",
        "        Args:\n",
        "            X_test: Test features\n",
        "            y_test: True test labels/values\n",
        "\n",
        "        Returns:\n",
        "            metrics: Dictionary with metric names and values\n",
        "                    e.g., {'rmse': 0.5, 'mae': 0.3, 'r2': 0.85}\n",
        "\n",
        "        You should implement:\n",
        "            - Get predictions on test data\n",
        "            - Compute appropriate metrics based on task_type:\n",
        "              * Regression: RMSE, MAE, R, MAPE\n",
        "              * Classification: Accuracy, Precision, Recall, F1\n",
        "            - Return metrics as a dictionary\n",
        "\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def save(self, filepath: str):\n",
        "        \"\"\"\n",
        "        Save your trained model to a file.\n",
        "\n",
        "        Args:\n",
        "            filepath: Path where to save (e.g., 'models/my_model.pkl')\n",
        "\n",
        "        You should implement:\n",
        "            - Save model parameters/weights\n",
        "            - Save any preprocessing parameters (mean, std, etc.)\n",
        "            - Save hyperparameters\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def load(self, filepath: str):\n",
        "        \"\"\"\n",
        "        Load a previously saved model.\n",
        "\n",
        "        Args:\n",
        "            filepath: Path to the saved model file\n",
        "\n",
        "        You should implement:\n",
        "            - Load model parameters/weights\n",
        "            - Load preprocessing parameters\n",
        "            - Restore the model to a usable state\n",
        "\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    '''\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "Example: Simple Linear Regression Model\n",
        "\n",
        "This shows you exactly what to implement.\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "\n",
        "class SimpleLinearRegression(BaseForecastModel):\n",
        "    \"\"\"\n",
        "    A simple linear regression model: y = X @ weights + bias\n",
        "\n",
        "    This is a minimal example showing all required methods.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, task_type='regression', learning_rate=0.01):\n",
        "        # Call parent constructor\n",
        "        super().__init__(task_type=task_type, learning_rate=learning_rate)\n",
        "\n",
        "        # Initialize model parameters\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        \"\"\"Train using closed-form solution.\"\"\"\n",
        "        # Add bias column to X\n",
        "        X_with_bias = np.column_stack([np.ones(len(X_train)), X_train])\n",
        "\n",
        "        # Closed-form solution: weights = (X^T X)^-1 X^T y\n",
        "        self.weights = np.linalg.lstsq(X_with_bias, y_train, rcond=None)[0]\n",
        "\n",
        "        # Split weights into bias and coefficients\n",
        "        self.bias = self.weights[0]\n",
        "        self.weights = self.weights[1:]\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Make predictions.\"\"\"\n",
        "        if self.weights is None:\n",
        "            raise ValueError(\"Model not trained! Call fit() first.\")\n",
        "\n",
        "        # y = X @ weights + bias\n",
        "        predictions = X @ self.weights + self.bias\n",
        "        return predictions\n",
        "\n",
        "    def evaluate(self, X_test, y_test):\n",
        "        \"\"\"Compute evaluation metrics.\"\"\"\n",
        "        predictions = self.predict(X_test)\n",
        "\n",
        "        # Calculate metrics\n",
        "        mse = np.mean((y_test - predictions) ** 2)\n",
        "        rmse = np.sqrt(mse)\n",
        "        mae = np.mean(np.abs(y_test - predictions))\n",
        "\n",
        "        # R score\n",
        "        ss_total = np.sum((y_test - np.mean(y_test)) ** 2)\n",
        "        ss_residual = np.sum((y_test - predictions) ** 2)\n",
        "        r2 = 1 - (ss_residual / ss_total)\n",
        "\n",
        "        return {\n",
        "            'mse': mse,\n",
        "            'rmse': rmse,\n",
        "            'mae': mae,\n",
        "            'r2': r2\n",
        "        }\n",
        "\n",
        "    def save(self, filepath: str):\n",
        "        \"\"\"Save the model.\"\"\"\n",
        "        save_dict = {\n",
        "            'weights': self.weights,\n",
        "            'bias': self.bias,\n",
        "            'learning_rate': self.learning_rate,\n",
        "            'task_type': self.task_type\n",
        "        }\n",
        "\n",
        "        with open(filepath, 'wb') as f:\n",
        "            pickle.dump(save_dict, f)\n",
        "\n",
        "        print(f\"Model saved to {filepath}\")\n",
        "\n",
        "    def load(self, filepath: str):\n",
        "        \"\"\"Load the model.\"\"\"\n",
        "        with open(filepath, 'rb') as f:\n",
        "            save_dict = pickle.load(f)\n",
        "\n",
        "        self.weights = save_dict['weights']\n",
        "        self.bias = save_dict['bias']\n",
        "        self.learning_rate = save_dict['learning_rate']\n",
        "\n",
        "        print(f\"Model loaded from {filepath}\")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# Example of execution on synthetic data\n",
        "# ============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 1. Create some data\n",
        "    X_train = np.random.randn(100, 5)\n",
        "    y_train = X_train @ np.array([1, 2, 3, 4, 5]) + np.random.randn(100) * 0.1\n",
        "\n",
        "    X_test = np.random.randn(20, 5)\n",
        "    y_test = X_test @ np.array([1, 2, 3, 4, 5]) + np.random.randn(20) * 0.1\n",
        "\n",
        "    # 2. Create and train model\n",
        "    model = SimpleLinearRegression(learning_rate=0.01)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # 3. Make predictions\n",
        "    predictions = model.predict(X_test)\n",
        "    print(\"Predictions:\", predictions[:5])\n",
        "\n",
        "    # 4. Evaluate\n",
        "    metrics = model.evaluate(X_test, y_test)\n",
        "    print(\"\\nMetrics:\")\n",
        "    for name, value in metrics.items():\n",
        "        print(f\"  {name}: {value:.4f}\")\n",
        "\n",
        "    # 5. Save and load\n",
        "    model.save('linear_model.pkl')\n",
        "\n",
        "    new_model = SimpleLinearRegression()\n",
        "    new_model.load('linear_model.pkl')\n",
        "\n",
        "    # Test loaded model\n",
        "    new_predictions = new_model.predict(X_test)\n",
        "    print(f\"\\nLoaded model works: {np.allclose(predictions, new_predictions)}\")\n",
        "\n",
        "    '''\n",
        "\n"
      ],
      "metadata": {
        "id": "-dVjlyI8yd9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f84cd6fb"
      },
      "source": [
        "# Task\n",
        "Prepare the `train`, `val`, and `test` DataFrames for time series forecasting. This involves:\n",
        "1. Extracting the 'Price' column as the target variable (`y_train`, `y_val`, `y_test`).\n",
        "2. Removing 'Date' and 'sasdate' columns from the DataFrames to form the feature sets (`X_train`, `X_val`, `X_test`).\n",
        "3. Generating sequences of 30 days from the feature sets, where the target for each sequence is the 'Price' value immediately following the sequence. The first 30 prices should be skipped.\n",
        "4. Converting the resulting feature and target NumPy arrays into PyTorch tensors.\n",
        "5. Finally, confirm the shapes of the created feature and target tensors for the train, validation, and test sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf2b4d7a"
      },
      "source": [
        "## Prepare Features and Target\n",
        "\n",
        "\n",
        "Extract the 'Price' column as the target variable and remove 'Date' and 'sasdate' columns from the `train` DataFrame to create the feature set. The resulting feature set will be used to create sequences.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93327fae"
      },
      "source": [
        "**Reasoning**:\n",
        "To prepare the feature and target variables as instructed, create `y_train` from the 'Price' column and `X_train` by dropping the specified columns from the `train` DataFrame, resetting their indices, and then displaying the first five rows of both for verification.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c68259fd",
        "outputId": "c6937452-a67e-4f37-ac91-d6f7e0dbba7c"
      },
      "source": [
        "y_train = train['Price'].reset_index(drop=True)\n",
        "X_train = train.drop(columns=['Date', 'sasdate', 'Price']).reset_index(drop=True)\n",
        "\n",
        "print(\"X_train head:\")\n",
        "print(X_train.head())\n",
        "print(\"\\ny_train head:\")\n",
        "print(y_train.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train head:\n",
            "        RPI  W875RX1   CMRMTSPLx  IPFPNSS  USWTRADE  USTRADE  BUSLOANS  \\\n",
            "0  6319.274   5489.2  535378.168  55.2854    4478.5  10509.0  392.4259   \n",
            "1  6351.636   5514.5  543698.110  55.6149    4491.5  10541.3  391.4906   \n",
            "2  6351.636   5514.5  543698.110  55.6149    4491.5  10541.3  391.4906   \n",
            "3  6351.636   5514.5  543698.110  55.6149    4491.5  10541.3  391.4906   \n",
            "4  6351.636   5514.5  543698.110  55.6149    4491.5  10541.3  391.4906   \n",
            "\n",
            "       CONSPI  S&P 500  S&P PE ratio  ...  T5YFFM  T10YFFM  AAAFFM  BAAFFM  \\\n",
            "0  112.909566    157.7     11.616356  ...    1.22     1.60    2.71    4.49   \n",
            "1  112.375069    164.1     12.216329  ...    1.40     1.75    2.83    4.46   \n",
            "2  112.375069    164.1     12.216329  ...    1.40     1.75    2.83    4.46   \n",
            "3  112.375069    164.1     12.216329  ...    1.40     1.75    2.83    4.46   \n",
            "4  112.375069    164.1     12.216329  ...    1.40     1.75    2.83    4.46   \n",
            "\n",
            "   EXSZUSx   EXJPUSx  EXUSUKx  EXCAUSx  PPICMM  UMCSENTx  \n",
            "0   2.0587  237.7467   1.5361   1.2325   102.1      89.1  \n",
            "1   2.0572  234.7557   1.5722   1.2292   103.3      93.3  \n",
            "2   2.0572  234.7557   1.5722   1.2292   103.3      93.3  \n",
            "3   2.0572  234.7557   1.5722   1.2292   103.3      93.3  \n",
            "4   2.0572  234.7557   1.5722   1.2292   103.3      93.3  \n",
            "\n",
            "[5 rows x 31 columns]\n",
            "\n",
            "y_train head:\n",
            "0    29.27\n",
            "1    29.44\n",
            "2    29.71\n",
            "3    29.90\n",
            "4    30.17\n",
            "Name: Price, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27faa133"
      },
      "source": [
        "**Reasoning**:\n",
        "Following the same logic as for the training set, extract the 'Price' column as the target variable and remove 'Date' and 'sasdate' columns from the `val` and `test` DataFrames to create the feature sets for validation and testing.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35649f23",
        "outputId": "6343c0a4-5557-4e26-cbc5-5b4df02bca33"
      },
      "source": [
        "y_val = val['Price'].reset_index(drop=True)\n",
        "X_val = val.drop(columns=['Date', 'sasdate', 'Price']).reset_index(drop=True)\n",
        "\n",
        "y_test = test['Price'].reset_index(drop=True)\n",
        "X_test = test.drop(columns=['Date', 'sasdate', 'Price']).reset_index(drop=True)\n",
        "\n",
        "print(\"X_val head:\")\n",
        "print(X_val.head())\n",
        "print(\"\\ny_val head:\")\n",
        "print(y_val.head())\n",
        "print(\"\\nX_test head:\")\n",
        "print(X_test.head())\n",
        "print(\"\\ny_test head:\")\n",
        "print(y_test.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_val head:\n",
            "         RPI  W875RX1  CMRMTSPLx  IPFPNSS  USWTRADE  USTRADE   BUSLOANS  \\\n",
            "0  19062.795  15496.6  1485162.0  98.6614    5852.7  15407.9  2486.9777   \n",
            "1  19062.795  15496.6  1485162.0  98.6614    5852.7  15407.9  2486.9777   \n",
            "2  19062.795  15496.6  1485162.0  98.6614    5852.7  15407.9  2486.9777   \n",
            "3  19062.795  15496.6  1485162.0  98.6614    5852.7  15407.9  2486.9777   \n",
            "4  19062.795  15496.6  1485162.0  98.6614    5852.7  15407.9  2486.9777   \n",
            "\n",
            "       CONSPI  S&P 500  S&P PE ratio  ...  T5YFFM  T10YFFM  AAAFFM  BAAFFM  \\\n",
            "0  161.999286  4573.82      28.27503  ...    1.46     1.68    2.85     3.5   \n",
            "1  161.999286  4573.82      28.27503  ...    1.46     1.68    2.85     3.5   \n",
            "2  161.999286  4573.82      28.27503  ...    1.46     1.68    2.85     3.5   \n",
            "3  161.999286  4573.82      28.27503  ...    1.46     1.68    2.85     3.5   \n",
            "4  161.999286  4573.82      28.27503  ...    1.46     1.68    2.85     3.5   \n",
            "\n",
            "   EXSZUSx   EXJPUSx  EXUSUKx  EXCAUSx   PPICMM  UMCSENTx  \n",
            "0   0.9191  114.8255   1.3555   1.2622  282.527      67.2  \n",
            "1   0.9191  114.8255   1.3555   1.2622  282.527      67.2  \n",
            "2   0.9191  114.8255   1.3555   1.2622  282.527      67.2  \n",
            "3   0.9191  114.8255   1.3555   1.2622  282.527      67.2  \n",
            "4   0.9191  114.8255   1.3555   1.2622  282.527      67.2  \n",
            "\n",
            "[5 rows x 31 columns]\n",
            "\n",
            "y_val head:\n",
            "0    66.27\n",
            "1    66.10\n",
            "2    69.30\n",
            "3    71.84\n",
            "4    72.18\n",
            "Name: Price, dtype: float64\n",
            "\n",
            "X_test head:\n",
            "         RPI  W875RX1  CMRMTSPLx  IPFPNSS  USWTRADE  USTRADE   BUSLOANS  \\\n",
            "0  20388.396  16635.4  1531801.0   96.329    6174.4  15573.2  2664.2775   \n",
            "1  20388.396  16635.4  1531801.0   96.329    6174.4  15573.2  2664.2775   \n",
            "2  20388.396  16635.4  1531801.0   96.329    6174.4  15573.2  2664.2775   \n",
            "3  20388.396  16635.4  1531801.0   96.329    6174.4  15573.2  2664.2775   \n",
            "4  20388.396  16635.4  1531801.0   96.329    6174.4  15573.2  2664.2775   \n",
            "\n",
            "       CONSPI  S&P 500  S&P PE ratio  ...  T5YFFM  T10YFFM  AAAFFM  BAAFFM  \\\n",
            "0  142.879141  5979.52     29.798731  ...     0.1      0.3    1.13    1.75   \n",
            "1  142.879141  5979.52     29.798731  ...     0.1      0.3    1.13    1.75   \n",
            "2  142.879141  5979.52     29.798731  ...     0.1      0.3    1.13    1.75   \n",
            "3  142.879141  5979.52     29.798731  ...     0.1      0.3    1.13    1.75   \n",
            "4  142.879141  5979.52     29.798731  ...     0.1      0.3    1.13    1.75   \n",
            "\n",
            "   EXSZUSx   EXJPUSx  EXUSUKx  EXCAUSx   PPICMM  UMCSENTx  \n",
            "0   0.9096  156.4819   1.2354   1.4389  286.942      71.7  \n",
            "1   0.9096  156.4819   1.2354   1.4389  286.942      71.7  \n",
            "2   0.9096  156.4819   1.2354   1.4389  286.942      71.7  \n",
            "3   0.9096  156.4819   1.2354   1.4389  286.942      71.7  \n",
            "4   0.9096  156.4819   1.2354   1.4389  286.942      71.7  \n",
            "\n",
            "[5 rows x 31 columns]\n",
            "\n",
            "y_test head:\n",
            "0    67.84\n",
            "1    69.54\n",
            "2    68.19\n",
            "3    67.96\n",
            "4    66.98\n",
            "Name: Price, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8ca8c1f"
      },
      "source": [
        "**Reasoning**:\n",
        "The next step is to generate sequences of 30 days from the feature sets (`X_train`, `X_val`, `X_test`) and their corresponding target values (`y_train`, `y_val`, `y_test`). Define a helper function to achieve this, ensuring the first 30 prices are skipped for target generation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72ae88da",
        "outputId": "1a4a1ab4-d151-44be-8021-b9ba96be04e2"
      },
      "source": [
        "def create_sequences(X, y, sequence_length=30):\n",
        "    xs, ys = [], []\n",
        "    # Iterate from sequence_length to the end of the data\n",
        "    # The target y[i] corresponds to the price after the sequence ending at X[i-1]\n",
        "    # So, the sequence is X[i - sequence_length : i] and the target is y[i]\n",
        "    for i in range(sequence_length, len(X)):\n",
        "        xs.append(X.iloc[i - sequence_length:i].values)\n",
        "        ys.append(y.iloc[i].item()) # .item() extracts scalar from Series element\n",
        "    return np.array(xs), np.array(ys)\n",
        "\n",
        "sequence_length = 30\n",
        "\n",
        "X_train_seq, y_train_seq = create_sequences(X_train, y_train, sequence_length)\n",
        "X_val_seq, y_val_seq = create_sequences(X_val, y_val, sequence_length)\n",
        "X_test_seq, y_test_seq = create_sequences(X_test, y_test, sequence_length)\n",
        "\n",
        "print(f\"X_train_seq shape: {X_train_seq.shape}\")\n",
        "print(f\"y_train_seq shape: {y_train_seq.shape}\")\n",
        "print(f\"X_val_seq shape: {X_val_seq.shape}\")\n",
        "print(f\"y_val_seq shape: {y_val_seq.shape}\")\n",
        "print(f\"X_test_seq shape: {X_test_seq.shape}\")\n",
        "print(f\"y_test_seq shape: {y_test_seq.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_seq shape: (9779, 30, 31)\n",
            "y_train_seq shape: (9779,)\n",
            "X_val_seq shape: (759, 30, 31)\n",
            "y_val_seq shape: (759,)\n",
            "X_test_seq shape: (162, 30, 31)\n",
            "y_test_seq shape: (162,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a925b082"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the sequences have been generated as NumPy arrays, convert them into PyTorch tensors, as required by the task, to prepare them for the PyTorch model. Then print the shapes of the tensors to confirm the conversion.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1bd26c3",
        "outputId": "556e8d44-6452-4d95-8464-9229a6b22077"
      },
      "source": [
        "X_train_tensor = torch.tensor(X_train_seq, dtype=torch.float32).view(X_train_seq.shape[0], -1)\n",
        "y_train_tensor = torch.tensor(y_train_seq, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "X_val_tensor = torch.tensor(X_val_seq, dtype=torch.float32).view(X_val_seq.shape[0], -1)\n",
        "y_val_tensor = torch.tensor(y_val_seq, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "X_test_tensor = torch.tensor(X_test_seq, dtype=torch.float32).view(X_test_seq.shape[0], -1)\n",
        "y_test_tensor = torch.tensor(y_test_seq, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "print(f\"X_train_tensor shape: {X_train_tensor.shape}\")\n",
        "print(f\"y_train_tensor shape: {y_train_tensor.shape}\")\n",
        "print(f\"X_val_tensor shape: {X_val_tensor.shape}\")\n",
        "print(f\"y_val_tensor shape: {y_val_tensor.shape}\")\n",
        "print(f\"X_test_tensor shape: {X_test_tensor.shape}\")\n",
        "print(f\"y_test_tensor shape: {y_test_tensor.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_tensor shape: torch.Size([9779, 930])\n",
            "y_train_tensor shape: torch.Size([9779, 1])\n",
            "X_val_tensor shape: torch.Size([759, 930])\n",
            "y_val_tensor shape: torch.Size([759, 1])\n",
            "X_test_tensor shape: torch.Size([162, 930])\n",
            "y_test_tensor shape: torch.Size([162, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the Bi-*GRU*"
      ],
      "metadata": {
        "id": "3Kl5MnUq7UJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "class _BiGRUModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Internal PyTorch Module for Bi-GRU with Attention and Skip Connections.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=2, dropout=0.2):\n",
        "        super(_BiGRUModel, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # Bidirectional GRU layers\n",
        "        self.gru = nn.GRU(\n",
        "            input_size=input_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=True,\n",
        "            dropout=dropout if num_layers > 1 else 0\n",
        "        )\n",
        "\n",
        "        # Attention Mechanism\n",
        "        # We will use a simple dot-product attention\n",
        "        self.attention = nn.Linear(hidden_dim * 2, 1)\n",
        "\n",
        "        # Skip Connection (Residual)\n",
        "        # We project input to hidden_dim * 2 to match GRU output if dims differ\n",
        "        self.skip_projection = nn.Linear(input_dim, hidden_dim * 2)\n",
        "\n",
        "        # Output Layers\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch_size, seq_len, input_dim)\n",
        "\n",
        "        # GRU Output: (batch_size, seq_len, hidden_dim * 2)\n",
        "        gru_out, _ = self.gru(x)\n",
        "\n",
        "        # Attention scores\n",
        "        # (batch_size, seq_len, 1)\n",
        "        attn_scores = self.attention(gru_out)\n",
        "        attn_weights = torch.softmax(attn_scores, dim=1)\n",
        "\n",
        "        # Context vector (weighted sum of GRU outputs)\n",
        "        # (batch_size, hidden_dim * 2)\n",
        "        context_vector = torch.sum(attn_weights * gru_out, dim=1)\n",
        "\n",
        "        # Skip Connection\n",
        "        # We take the last input of the sequence for the skip connection\n",
        "        # (batch_size, input_dim) -> (batch_size, hidden_dim * 2)\n",
        "        skip_input = x[:, -1, :]\n",
        "        skip_out = self.skip_projection(skip_input)\n",
        "\n",
        "        # Combine Context and Skip\n",
        "        combined = context_vector + skip_out\n",
        "\n",
        "        # Output\n",
        "        out = self.fc(combined)\n",
        "        return out"
      ],
      "metadata": {
        "id": "VqT2JQjIyGN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BiGRUAttentionModel(BaseForecastModel):\n",
        "    \"\"\"\n",
        "    Bi-GRU with Attention and Skip Connections for Time Series Forecasting.\n",
        "    \"\"\"\n",
        "    def __init__(self, task_type='regression', input_dim=930, hidden_dim=24, num_layers=4, dropout=0.2, learning_rate=0.003, epochs=10, batch_size=32):\n",
        "        super().__init__(task_type=task_type, input_dim=input_dim, hidden_dim=hidden_dim, num_layers=num_layers, dropout=dropout, learning_rate=learning_rate, epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout = dropout\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.model = None\n",
        "        self.criterion = None\n",
        "        self.optimizer = None\n",
        "\n",
        "        # Device configuration\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "\n",
        "        if not self.model:\n",
        "            self.model = _BiGRUModel(\n",
        "            input_dim=self.input_dim,\n",
        "            hidden_dim=self.hidden_dim,\n",
        "            output_dim=1, # output dimension is 1 since we are predicting one value\n",
        "            num_layers=self.num_layers,\n",
        "            dropout=self.dropout\n",
        "            ).to(self.device)\n",
        "\n",
        "            self.criterion = nn.MSELoss()\n",
        "            self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
        "\n",
        "        \"\"\"\n",
        "        Train the model using PyTorch training loop.\n",
        "        X_train shape: (num_samples, seq_len, input_dim)\n",
        "        y_train shape: (num_samples,)\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
        "        dataloader = torch.utils.data.DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "        self.model.train()\n",
        "        for epoch in range(self.epochs):\n",
        "            batch_losses = []\n",
        "            for batch_X, batch_y in dataloader:\n",
        "                self.optimizer.zero_grad()\n",
        "                outputs = self.model(batch_X)\n",
        "                loss = self.criterion(outputs, batch_y)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                batch_losses.append(loss.item())\n",
        "\n",
        "            # Optional: Print progress\n",
        "            if (epoch + 1) % max(1, self.epochs // 10) == 0:\n",
        "                print(f\"Epoch [{epoch+1}/{self.epochs}], Loss: {np.mean(batch_losses):.4f}\")\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Make predictions.\n",
        "        X shape: (num_samples, seq_len, input_dim)\n",
        "        \"\"\"\n",
        "        if self.model is None:\n",
        "             raise ValueError(\"Model not trained! Call fit() first.\")\n",
        "\n",
        "        self.model.eval()\n",
        "        X_tensor = torch.tensor(X, dtype=torch.float32).to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            predictions = self.model(X_tensor).cpu().numpy()\n",
        "\n",
        "        return predictions.flatten()\n",
        "\n",
        "    def evaluate(self, X_test, y_test):\n",
        "        \"\"\"\n",
        "        Evaluate the model.\n",
        "        \"\"\"\n",
        "        predictions = self.predict(X_test)\n",
        "\n",
        "        mse = np.mean((y_test - predictions) ** 2)\n",
        "        rmse = np.sqrt(mse)\n",
        "        mae = np.mean(np.abs(y_test - predictions))\n",
        "\n",
        "        # R score\n",
        "        ss_total = np.sum((y_test - np.mean(y_test)) ** 2)\n",
        "        ss_residual = np.sum((y_test - predictions) ** 2)\n",
        "        r2 = 1 - (ss_residual / ss_total) if ss_total != 0 else 0\n",
        "\n",
        "        return {\n",
        "            'mse': mse,\n",
        "            'rmse': rmse,\n",
        "            'mae': mae,\n",
        "            'r2': r2\n",
        "        }\n",
        "\n",
        "    def save(self, filepath: str):\n",
        "        \"\"\"\n",
        "        Save model state and hyperparameters.\n",
        "        \"\"\"\n",
        "        state = {\n",
        "            'model_state_dict': self.model.state_dict(),\n",
        "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "            'hyperparameters': self.hyperparameters,\n",
        "             # Also save the explicitly stored attributes in case they were modified or needed\n",
        "            'config': {\n",
        "                'input_dim': self.input_dim,\n",
        "                'hidden_dim': self.hidden_dim,\n",
        "                'num_layers': self.num_layers,\n",
        "                'dropout': self.dropout,\n",
        "                'learning_rate': self.learning_rate,\n",
        "                'epochs': self.epochs,\n",
        "                'batch_size': self.batch_size\n",
        "            }\n",
        "        }\n",
        "        torch.save(state, filepath)\n",
        "        print(f\"Model saved to {filepath}\")\n",
        "\n",
        "    def load(self, filepath: str):\n",
        "        \"\"\"\n",
        "        Load model state.\n",
        "        \"\"\"\n",
        "        checkpoint = torch.load(filepath, map_location=self.device)\n",
        "\n",
        "        # Restore hyperparameters\n",
        "        config = checkpoint.get('config', {})\n",
        "        self.input_dim = config.get('input_dim', self.input_dim)\n",
        "        self.hidden_dim = config.get('hidden_dim', self.hidden_dim)\n",
        "        self.num_layers = config.get('num_layers', self.num_layers)\n",
        "        self.dropout = config.get('dropout', self.dropout)\n",
        "        self.learning_rate = config.get('learning_rate', self.learning_rate)\n",
        "        # Note: epochs and batch_size are mainly for training, so restoring them is optional but good practice\n",
        "        self.epochs = config.get('epochs', self.epochs)\n",
        "        self.batch_size = config.get('batch_size', self.batch_size)\n",
        "\n",
        "        # Rebuild model matches the saved config\n",
        "        self._build_model()\n",
        "\n",
        "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        print(f\"Model loaded from {filepath}\")"
      ],
      "metadata": {
        "id": "B2BzqCzO7Kow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    # Synthetic Data Test\n",
        "    print(\"Generating synthetic data...\")\n",
        "    # Generate random sequences: (num_samples, seq_len, input_dim)\n",
        "    N = 1000\n",
        "    seq_len = 10\n",
        "    input_dim = 1\n",
        "\n",
        "    X = np.random.randn(N, seq_len, input_dim)\n",
        "    # Simple target: sum of the sequence plus some noise\n",
        "    y = np.sum(X, axis=1).flatten() + np.random.randn(N) * 0.1\n",
        "\n",
        "    # Split\n",
        "    split = int(0.8 * N)\n",
        "    X_train, X_test = X[:split], X[split:]\n",
        "    y_train, y_test = y[:split], y[split:]\n",
        "\n",
        "    print(\"Initializing model...\")\n",
        "    model = BiGRUAttentionModel(\n",
        "        input_dim=input_dim,\n",
        "        hidden_dim=32,\n",
        "        num_layers=1,\n",
        "        epochs=5,\n",
        "        batch_size=32\n",
        "    )\n",
        "\n",
        "    print(\"Training model...\")\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    print(\"Evaluating model...\")\n",
        "    metrics = model.evaluate(X_test, y_test)\n",
        "    print(\"Metrics:\", metrics)\n",
        "\n",
        "    print(\"Testing Save/Load...\")\n",
        "    model.save('test_bi_gru_model.pth')\n",
        "\n",
        "    loaded_model = BiGRUAttentionModel(input_dim=input_dim, hidden_dim=32, num_layers=1)\n",
        "    loaded_model.load('test_bi_gru_model.pth')\n",
        "\n",
        "    # Check predictions match\n",
        "    pred_orig = model.predict(X_test[:5])\n",
        "    pred_load = loaded_model.predict(X_test[:5])\n",
        "\n",
        "    print(\"Original Predictions:\", pred_orig)\n",
        "    print(\"Loaded Predictions:  \", pred_load)\n",
        "    print(\"Match:\", np.allclose(pred_orig, pred_load))\n"
      ],
      "metadata": {
        "id": "xFsMArGh7N-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4vpjbbEz7fs-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}